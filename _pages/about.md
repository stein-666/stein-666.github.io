---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

HiðŸ‘‹, I am Tongcheng, currently a master's student in the [NICS-EFC Lab](https://nicsefc.ee.tsinghua.edu.cn/) ([EffAlg](https://nics-effalg.com/)) at the Department of Electronic Engineering, Tsinghua University. Iâ€™m now advised by [Professor Wang Yu](https://nicsefc.ee.tsinghua.edu.cn/people/YuWang), [Professor Ding Wenbo](https://ssr-group.net/), and [Dr. Ning Xuefei](https://nics-effalg.com/ningxuefei/). I received my Bachelor's degree from the Beijing Institute of Technology in 2024. My research focuses on efficient visual generation, and recently, I've also become interested in agent system. I warmly welcome opportunities for collaboration or discussionâ€”feel free to reach me out!


Internship
======
[Aug 2023 â€“ Jul 2025] Infinigence AI, Algorithm Research Intern. [Website](https://cloud.infini-ai.com/platform/ai)


Publications
======
\* indicates equal contribution

[[MM 25] **DLFR-VAE: Dynamic Latent Frame Rate VAE for Video Generation**](https://arxiv.org/pdf/2502.11897)  
We propose the Dynamic Latent Frame Rate VAE (DLFR-VAE), a training-free paradigm that can make use of adaptive temporal compression in latent space.
Zhihang Yuan, Siyuan Wang, Rui Xie, Hanling Zhang, **Tongcheng Fang**, Yuzhang Shang, Shengen Yan, Guohao Dai, Yu Wang

[[arXiv 25] **E-CAR: Efficient Continuous Autoregressive Image Generation via Multistage Modeling**](https://arxiv.org/pdf/2412.14170)  
We presents E-CAR, an efficient autoregressive image generation model with cascaded modeling in continuous latent space.
Zhihang Yuan, Yuzhang Shang, Hanling Zhang, **Tongcheng Fang**, Rui Xie, Bingxin Xu, Yan Yan, Shengen Yan, Guohao Dai, Yu Wang

[[ICLR 25] **ViDiT-Q: Efficient and Accurate Quantization of Diffusion Transformers for Image and Video Generation**](https://arxiv.org/pdf/2406.02540)  
We introduce ViDiT-Q, a quantization method specialized for diffusion transformers. For popular large-scale models (e.g., open-sora, Latte, Pixart-Î±, Pixart-Î£) for the video and image generation task, ViDiT-Q could achieve W8A8 quantization without metric degradation, and W4A8 without notable visual quality degradation.  
*Tianchen Zhao, **Tongcheng Fang**, Haofeng Huang, Enshu Liu, Rui Wan, Widyadewi Soedarmadji, Shiyao Li, Zinan Lin, Guohao Dai, Shengen Yan, Huazhong Yang, Xuefei Ning, Yu Wang*

[[ECCV24] **MixDQ: Memory-Efficient Few-Step Text-to-Image Diffusion Models with Metric-Decoupled Mixed Precision Quantization**](https://arxiv.org/pdf/2405.17873)  
We design MixDQ, a mixed-precision quantization framework that successfully tackles the challenging few-step text-to-image diffusion model quantization. With negligible visual quality degradation and content change, MixDQ could achieve W4A8, with equivalent 3.4x memory compression and 1.5x latency speedup.  
*Tianchen Zhao\*, Xuefei Ning\*, **Tongcheng Fang**\*, Enshu Liu, Guyue Huang, Zinan Lin, Shengen Yan, Guohao Dai, Yu Wang*  


Please review my [Google Scholar profile](https://scholar.google.com/citations?user=tA7BRgQAAAAJ&hl=en) to view more.

